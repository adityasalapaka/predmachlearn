hatvalues(fit)
dfbeta(fit)
dfbeta(fit)
dfbetas(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
dfbeta(fit)
hatvalues(fit)
dfbetas(fit)
rm(list()=lm)
rm(list)
?mtcars
str(mtcars)
data(mtcars)
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
str(mtcars)
pairs(mtcars)
install.packages("GGally")
ggpairs(mtcars)
library("GGally")
ggpairs(mtcars)
examples(ggpairs)
?ggpairs
ggpairs(mtcars, axisLabels = "internal")
g <- ggplot(mtcars, aes(am, mpg))
library("ggplot2")
g <- ggplot(mtcars, aes(am, mpg))
g <- g + geom_boxplot()
print(g)
g <- g + geom_boxplot() + xlab("Transmission Type") + ylab("MPG")
print(g)
g <- g + geom_boxplot() + xlab("Transmission Type") + ylab("MPG") + geom_jitter()
print(g)
?step
inital <- lm(mpg ~ ., data = mtcars)
best <- step(initial, direction = "both")
initial <- lm(mpg ~ ., data = mtcars)
best <- step(initial, direction = "both")
summary(best)
anova(initial, best)
anova(best, initial)
anova(lm(mpg ~ am), best)
anova(lm(mpg ~ am, data = mtcars), best)
anova(lm(mpg ~ am, data = mtcars), best)$pr
anova(lm(mpg ~ am, data = mtcars), best)$Pr
anova(lm(mpg ~ am, data = mtcars), best)$P
anova(lm(mpg ~ am, data = mtcars), best)$R
anova(lm(mpg ~ am, data = mtcars), best)$R2
?anova
base <- lm(mpg ~ am, data = mtcars)
anova(base, best)
str(anova(base, best))
str(summary(best))
resid(best)
plot(resid)
plot(density(resid))
plot(resid(best))
plot(density(resid(best)))
qqnorm(resid(best))
ggplot(resid(best))
qqline(resid(best))
plot(mtcars)
qqline(resid(best))
qqplot(resid(best))
qqnorm(resid(best))
qqline(resid(best))
?qqnorm
qqnorm(resid(best), datax = TRUE)
plot(best)
par(mfrow = c(2,2))
plot(best)
ggpairs(mtcars, axisLabels = "internal", alpha = 0.4)
par(mfrow = c(2,2))
plot(best)
hatvalues(best)
sort(hatvalues(best))
sort(defbetas(best))
sort(dfbetas(best))
dfbetas(best)
dfbetas(best)[6]
dfbetas(best)[,6]
tail(sort(hatvalues(best)), 3)
t.test(mpg ~ am, data = mtcars)
str(t.test(mpg ~ am, data = mtcars))
t.test(mpg ~ am, data = mtcars)$estimate
t.test(mpg ~ am, data = mtcars)$p
t.test(mpg ~ am, data = mtcars)$p.value
t.test(best)
plot(mpg ~ am, data = mtcars)
shapiro.test(mpg ~ am, data = mtcars)
shapiro.test(mpg ~ am)
shapiro.test(mtcars$mpg ~ mtcars$am)
shapiro.test(mtcars)
plot(lm(mpg ~ am), data = mtcars)
plot(lm(mpg ~ am, data = mtcars))
str(plot(lm(mpg ~ am, data = mtcars))))
str(plot(lm(mpg ~ am, data = mtcars)))
x <- plot(lm(mpg ~ am, data = mtcars))
x
print(x)
plot(lm(mpg ~ am, data = mtcars))
?par
par(mfrow = c(1,1))
plot(lm(mpg ~ am, data = mtcars))
plot(lm(mpg ~ am, data = mtcars), which = c(1))
plot(lm(mpg ~ am, data = mtcars), which = c(2))
plot(lm(mpg ~ am, data = mtcars), which = 2
)
plot(lm(mpg ~ am, data = mtcars), which = 2)
t.test(mpg ~ am, data = mtcars)$estimate
str(t.test(mpg ~ am, data = mtcars)$estimate)
t.test(mpg ~ am, data = mtcars)$estimate[1]
t.test(mpg ~ am, data = mtcars)$estimate[2]
?mtcars
str(best)
summary(best)
str(summary(best))
best[amManual]
best["amManual"]
best$coefficients
best$coefficients[6]
best
library("caret")
install.packages("caret")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(mixtures)
hist(mixture$Superplasticizer)
hist(mixtures$Superplasticizer)
hist(training$Superplasticizer)
log
hist(log(training$Superplasticizer))
log(training$Superplasticizer)
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
View(predictors)
training[,40]
str(training[,40])
str(training)
?names
training[,grep("^[IL]", names(training), value=TRUE)]
df <- training[,grep("^[IL]", names(training), value=TRUE)]
View(df)
df <- training[,grep("^IL", names(training), value=TRUE)]
View(df)
M <- abs(cor(df))
diag(M) <- 0
which(M > 0.8, arr.ind = T)
M <- abs(cor(df))
View(M)
?which
diag(M) <- 0
View(M)
which(M > 0.8)
which(M> 0.8)
which(M> 0.9)
?preProcess
preproc <- preProcess(df)
preproc
str(preproc)
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.9)
preProc$rotation
rm(list=ls())
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = df[ inTrain,]
testing = df[-inTrain,]
modelfit <- train(diagnosis ~ ., method = "glm", data = training)
install.packages("e1071")
modelfit <- train(diagnosis ~ ., method = "glm", data = training)
1
predictions <- predict(modelFit, newdata = testing)
predictions <- predict(modelfit, newdata = testing)
predictions
str(predictions)
confusionMatrix(predictions, testing$diagnosis)
?createDataPartition
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = df[ inTrain,]
testing = df[-inTrain,]
IL_str <- grep("^IL", colnames(training), value = TRUE)
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
modelfit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelfit, newdata = testing)
confusionMatrix(predictions, testing$diagnosis)
library(caret)
?createDataPartition
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain = createDataPartition(segmentationOriginal, p = 3/4)[[1]]
View(segmentationOriginal)
inTrain = createDataPartition(segmentationOriginal, p = 3/4)
inTrain = segmentationOriginal[segmentationOriginal$Case = "Train",]
inTrain = segmentationOriginal[segmentationOriginal$Case == "Train",]
View(inTrain)
set.seed(125)
library(ISLR)
install.packages("ISLR")
library(ISLR)
data(Wage)
library(ggplot2)
library(caret)
Wage <- subset(Wage, select=-c(lowage))
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
modFit <- train(wage ~ ., method = "gbm", data = training, verbose =FALSE)
warnings()
install.packages("ElemStatLearn")
install.packages("pgmm")
install.packages("rpart")
install.packages("rpart")
testing <- segmentationOriginal[segmentationOriginal$Case = "Test",]
training = segmentationOriginal[segmentationOriginal$Case == "Train",]
testing <- segmentationOriginal[segmentationOriginal$Case = "Test",]
training <- segmentationOriginal[segmentationOriginal$Case == "Train",]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
library(caret)
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
print(modFit)
install.packages("rattle")
print(modFit$FinalModel)
print(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
inTrain <- createDataPartition(y=olive, p=0.7, list=FALSE)
library(caret)
inTrain <- createDataPartition(y=olive, p=0.7, list=FALSE)
inTrain <- createDataPartition(y=olive$Area, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
modFit <- train(wage ~ ., method = "gbm", data = training, verbose =FALSE)
?tree
predict(modFit, newdata = as.data.frame(t(colMeans(olive)))
)
predict(modFit, newdata = as.data.frame(t(colMeans(olive))))
View(olive)
modFit <- train(wage ~ ., method = "gbm", data = training, verbose =FALSE)
fancyRpartPlot(modFit$finalModel)
modFit <- train(Area ~ ., method = "gbm", data = training, verbose =FALSE)
View(training)
library(pgmm)
data(olive)
olive = olive[,-1]
inTrain <- createDataPartition(y=olive$Area, p=0.7, list=FALSE)
training <- olive[inTrain,]
testing <- olive[-inTrain,]
modFit <- train(Area ~ ., method = "gbm", data = training, verbose =FALSE)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata = as.data.frame(t(colMeans(olive))))
?predict.tree
predict.tree(modFit)
colMeans(olive)
t(colMeans(olive))
modFit
fancyRpartPlot(modFit$finalModel)
?fancyRpartPlot
str(modFit)
summary(modFit)
library(pgmm)
data(olive)
olive = olive[,-1]
inTrain <- createDataPartition(y=olive$Area, list=FALSE)
training <- olive[inTrain,]
testing <- olive[-inTrain,]
modFit <- train(Area ~ ., method = "gbm", data = training, verbose =FALSE)
predict(modFit, newdata = as.data.frame(t(colMeans(olive))))
summary(modFit)
qplot(modFit)
plot(modFit)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
?train
set.seed(13234)
set.seed(13234)
View(SAheart)
mylogit <- glm(chd ~ tobacco + ldl + typea + obesity + alcohol + age)
mylogit <- glm(chd ~ tobacco + ldl + typea + obesity + alcohol + age, data = trainSA, family = "binomial")
summary(mylogit)
qplot(mylogit)
plot(mylogit)
hist(mylogit)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA, mylogit)
predict(mylogit, newdata = trainSA)
missClass(trainSA, predict(mylogit, newdata = trainSA))
predict(mylogit, newdata = testSA)
trainp <- predict(mylogit, newdata = trainSA)
testp <- predict(mylogit, newdata = testSA)
missClass(trainSA, trainp)
missClass(testSA, testp)
missClass(testp, trainSA)
missClass(testp, predict(mylogit, type = "response"))
missClass(trainp, predict(mylogit, type = "response"))
trainp <- predict(mylogit, newdata = trainSA, type = "response")
testp <- predict(mylogit, newdata = testSA, type = "response")
missClass(trainSA, trainp)
missClass(trainSA, testSA)
missClass(trainSA, testp)
missClass(testp, testp)
missClass(testSA, testp)
missClass(testSA$chd, testp)
missClass(trainSA$chd, trainp)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
View(vowel.train)
vowel.train$y <- factor(vovel.train$y)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
View(vowel.test)
set.seed(33833)
modFit <- train(y ~ ., data = vowel.train, method = "rf", prox = TRUE)
modFit <- train(y ~ ., data = vowel.train, method = "rf", prox = TRUE)
plot(modFit)
summary(modFit)
?varImp
varImp(modFit)
AppliedPredictiveModelling
AppliedPredictiveModeling
str(AppliedPredictiveModeling)
?AppliedPredictiveModeling
library("AppliedPredictiveModeling")
setwd("~/predmachlearn")
training <- read.csv("pml-testing.csv")
View(training)
testing <- read.csv("pml-testing.csv")
View(testing)
training <- read.csv("pml-training.csv")
View(training)
testing <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0", ""))
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0", ""))
View(training)
testing <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
View(testing)
View(training)
dim(testing)
dim(training)
is.na(training)
sum(is.na(training))
?is.na
sum(is.na(testing))
colSums(is.na(training))
?colSumsm
?colSums
View(colSums(is.na(training))
)
testing[1:7]
testing[,(1:7)]
testing[,c(1:7)]
head(testing[1:7])
head(testing-[1:7])
head(testing[-(1:7)])
str(testing[-(1:7)])
head(str(testing[-(1:7)]))
training <- training[-(1:7)]
View(training)
testing <- testing[-(1:7)]
colSums(is.na(training))
colSums(is.na(training)) == 0
training[colSums(is.na(training)) == 0]
training[,colSums(is.na(training)) == 0]
View[training[,colSums(is.na(training)) == 0]]
View(training[,colSums(is.na(training)) == 0])
View(training[,colSums(is.na(training)) != 0])
testing <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
training[-1]
str(training[-1])
View(testing)
testing <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
dim(testing)
dim(training)
training <- training[-(1:7)]
testing <- testing[-(1:7)]
training <- training[,colSums(is.na(training)) != 0]
testing <- testing[,colSums(is.na(testing)) != 0]
dim(testing)
dim(training)
library(caret)
?createDataPartition
?train
?rpart
set.seed(42)
set.seed(4200)
inTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
View(training)
training <- training[,colSums(is.na(training)) = 0]
testing <- testing[,colSums(is.na(testing)) = 0]
dim(testing)
#libraies
library(caret)
#loading
testing <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
dim(testing)
dim(training)
#cleanup
training <- training[-(1:7)]
testing <- testing[-(1:7)]
training <- training[,colSums(is.na(training)) = 0]
training <- training[,colSums(is.na(training)) == 0]
testing <- testing[,colSums(is.na(testing)) == 0]
dim(testing)
dim(training)
testing <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
dim(testing)
dim(training)
training <- training[-(1:7)]
testing <- testing[-(1:7)]
training <- training[,colSums(is.na(training)) == 0]
testing <- testing[,colSums(is.na(testing)) == 0]
View(training)
dim(testing)
dim(training)
#subsampling
set.seed(4200)
inTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
subtraining <- training[inTrain,]
subtesting <- training[-inTrain,]
#tree model
modFit <- train(classe ~ ., method = "rpart", data = subtraining)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
treeFit <- train(classe ~ ., method = "rpart", data = subtraining)
fancyRpartPlot(treeFit$finalModel)
plot(treeFit)
qplot(treeFit)
qplot(training)
plot(training)
treePredict <- predict(treeFit, newdata = subtesting)
nsv <- nearZeroVar(training, saveMetrics = TRUE)
nsv
?fancyRpartPlot
treeFit <- train(classe ~ ., method = "rpart", data = subtraining,
main = "Decision Tree", sub = "Rpart Decision Tree To Predict Classe")
fancyRpartPlot(treeFit$finalModel, main = "Decision Tree",
sub = "Rpart Decision Tree To Predict Classe")
confusionMatrix(treePredict, subtesting$classe)
getTree
forestFit <- train(classe ~ ., method = "rf", data = subtraining, prox = TRUE) #why prox?
