---
title: "Practical Machine Learning, Course Project"
author: "Aditya Salapaka"
date: "Friday 20 June 2015"
output: html_document
---

# Practical Machine Learning, Course Project

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible
to collect a large amount of data about personal activity relatively 
inexpensively. These type of devices are part of the quantified self movement â€“ 
a group of enthusiasts who take measurements about themselves regularly to 
improve their health, to find patterns in their behavior, or because they are 
tech geeks. One thing that people regularly do is quantify how much of a 
particular activity they do, but they rarely quantify how well they do it. 

Six young health participants were asked to perform one set of 10 repetitions of
the Unilateral Dumbbell Biceps Curl in five different fashions:

* Class A: exactly according to the specification
* Class B: throwing the elbows to the front
* Class C: lifting the dumbbell only halfway
* Class D: lowering the dumbbell only halfway
* Class E: throwing the hips to the front

The aim is to predict the manner in which the participants did the exercise.

## Data

The training data for this project are available [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv).

The test data are available [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)

## Required Libraries

The following libraries are required for this project:

```{r libraries, message=FALSE}
library(caret)
library(rpart)
library(rattle)
library(randomForest)
```

## Getting Data

The training and test data sets were downloaded from the links given above. 
They were saved in the working directory with their default filenames.

A quick overview of both datasets showed that NA values were registered as 
either `"NA"`, `"#DIV/0!"` or `""`. This argument was used in loading both the
datasets into the workspace.

```{r loading}
testing <- read.csv("pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))
training <- read.csv("pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
```

## Cleanup

Checking for the number of variables and rows in both sets:

```{r dim}
dim(testing)
dim(training)
```

Both sets have 160 variables, currently. 

From a glance at the training dataset, we see that the first seven variables
are unnecessary from a machine learning standpoint. These are eliminated from
both datasets.

```{r remove 1:7}
training <- training[-(1:7)]
testing <- testing[-(1:7)]
```

Further, there are some variables which contain no data at all, that is, are 
completely filled with NA values. These are also removed from the datasets.

```{r remove NA variables}
training <- training[,colSums(is.na(training)) == 0]
testing <- testing[,colSums(is.na(testing)) == 0]
```

Now, we need to eliminate the variables which cause nearly zero variance.

```{r zerovar}
nsv <- nearZeroVar(training, saveMetrics = TRUE)
sum(nsv$nzv)
```

We see that no variables provide near zero variance.

## Subsampling

The training set available is split into another training and test set, in a 
70:30 ratio for cross-validation purposes.

A seed of 4200 is set for the sake of reproducibility. 

```{r subsampling}
set.seed(4200)

inTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
subtraining <- training[inTrain,]
subtesting <- training[-inTrain,]
```

## Prediction Using Machine Learning Algorithms

### Decision Tree


```{r tree}
treeFit <- rpart(classe ~ ., method = "class", data = subtraining)
```

This is the decision tree generated.

```{r tree plot}
fancyRpartPlot(treeFit, main = "Decision Tree", 
               sub = "Rpart Decision Tree To Predict Classe")
```

Using the model to predict in the test subsample:

```{r tree predict}
treePredict <- predict(treeFit, subtesting, type = "class")
```

The accuracy of the prediction is checked using a confusion matrix.

```{r tree confusion matrix}
confusionMatrix(treePredict, subtesting$classe)
```

We obtain an accuracy of 73.81.

### Random Forest

```{r forest}
forestFit <- randomForest(classe ~ ., data = subtraining, method = "class")
```

Using the model to predict in the test subsample:

```{r forest predict}
forestPredict <- predict(forestFit, subtesting, type = "class")
```

The accuracy of the prediction is checked using a confusion matrix.

```{r forest confusion matrix}
confusionMatrix(forestPredict, subtesting$classe)
```

We obtain an accuracy of 99.51.